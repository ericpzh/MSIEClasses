{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "19\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-70f58a8894b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;31m#start=datetime.now()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstagewise_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthres\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_yhat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#% with logit g, 66% with lin g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;31m#print(test(generalized_least_squares(x,y,W0,L,g,n,d,k,thres),g)) #% with logit g, 16% with lin g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-70f58a8894b4>\u001b[0m in \u001b[0;36mstagewise_regression\u001b[1;34m(x, y, GEN, L, g, n, d, k, thres, p, T)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mx_tilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tilt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneralized_least_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tilt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#kxp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mWs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-70f58a8894b4>\u001b[0m in \u001b[0;36mgeneralized_least_squares\u001b[1;34m(x, y, W0, L, g, n, d, k, thres)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m       \u001b[0my_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import copy\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
    "\n",
    "def generalized_least_squares(x,y,W0,L,g,n,d,k,thres):\n",
    "  def is_close(a,b,thres):\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "      for j in range(len(a[i])):\n",
    "        s += abs(a[i][j] - b[i][j])\n",
    "    #print(s)\n",
    "    return s < thres \n",
    "\n",
    "  #compute sigma hat inverse\n",
    "  sigma_hat = np.zeros([d,d]) #dxd\n",
    "  for i in range(n):\n",
    "    sigma_hat = np.add(sigma_hat,np.matmul(np.transpose([x[:,i]]),np.array([x[:,i]])))\n",
    "  sigma_hat_inv = np.linalg.inv(1/n * np.around(sigma_hat,5)) #dxd\n",
    "\n",
    "  #print(sigma_hat_inv)\n",
    "    \n",
    "  #init W\n",
    "  prev_W = W0\n",
    "  W = W0\n",
    "\n",
    "  t = 0\n",
    "  while (t == 0 or not is_close(W,prev_W,thres)): #while not converge\n",
    "    t += 1\n",
    "    \n",
    "    prev_W = copy.deepcopy(W)\n",
    "\n",
    "    #compute y_hat = kxn\n",
    "    y_hat = []\n",
    "    \n",
    "    for i in range(n):\n",
    "      y_hat.append(np.array(g(np.matmul(W,np.array(x[:,i])))))\n",
    "    y_hat = np.transpose(np.array(y_hat))\n",
    "\n",
    "    #compute E_hat = kxd\n",
    "    E_hat = np.zeros([k,d])\n",
    "    for i in range(n):\n",
    "      E_hat = np.add(E_hat, np.matmul(np.transpose([y_hat[:,i] - y[:,i]]),np.array([x[:,i]])))\n",
    "    E_hat = E_hat / n\n",
    "\n",
    "\n",
    "    #compute W = kxd\n",
    "    W = np.add(np.transpose(prev_W), -1/L * np.matmul(sigma_hat_inv,np.transpose(E_hat)))\n",
    "    W = np.transpose(W)\n",
    "    \n",
    "    #print(t)\n",
    "  return W\n",
    "\n",
    "def stagewise_regression(x,y,GEN,L,g,n,d,k,thres,p=2,T=20):\n",
    "  i_sets = []\n",
    "  Ws = []\n",
    "    \n",
    "  y_hat = np.zeros([k,n]) #kxn\n",
    "\n",
    "  for t in range(T):\n",
    "    #sys.stdout.write(str(t))\n",
    "    #sys.stdout.flush()#print(t)\n",
    "    print(t)\n",
    "    x_tilt = [] #pxn\n",
    "    i_set = sorted(GEN(x,p))\n",
    "    i_sets.append(i_set)\n",
    "\n",
    "    for i in i_set:\n",
    "      x_tilt.append(x[i])\n",
    "    x_tilt = np.array(x_tilt)\n",
    "\n",
    "    W = generalized_least_squares(x_tilt,np.add(y,-y_hat),np.zeros([k,p]),L,g,n,p,k,thres) #kxp\n",
    "    Ws.append(W)\n",
    "    \n",
    "    new_y_hat = []\n",
    "    for i in range(n):\n",
    "      new_y_hat.append(y_hat[:,i] + np.matmul(W,x_tilt[:,i]))\n",
    "    y_hat = np.transpose(new_y_hat) #kxn\n",
    "   \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "      if(np.argmax(y_hat[:,i]) != np.nonzero(y[:,i])[0][0]):\n",
    "        count += 1\n",
    "    print(count)\n",
    "    \n",
    "  return (i_sets, Ws)\n",
    "\n",
    "n = 100\n",
    "d = 3\n",
    "k = 3\n",
    "p = 2\n",
    "T = 100\n",
    "thres = 0.01\n",
    "pca = PCA(n_components=d)\n",
    "x = np.transpose(pca.fit_transform(x_train))\n",
    "#x = np.transpose(x_train[:n])\n",
    "y = np.zeros([k,n])\n",
    "for i in range(n):\n",
    "  y[y_train[i]][i] = 1\n",
    "\n",
    "W0 = np.zeros([k,d])\n",
    "L = 1\n",
    "\n",
    "def g(u):\n",
    "  #return u\n",
    "  for i in range(len(u)):\n",
    "    if (u[i] < 10):\n",
    "      u[i] = np.exp(u[i])/(1+np.exp(u[i]))\n",
    "    else:\n",
    "      u[i] = 1 \n",
    "  return u\n",
    "\n",
    "def GEN(X,p): #return the idx of selected X or 'j' of X_j\n",
    "  arr = [i for i in range(len(X))]\n",
    "  np.random.shuffle(arr)\n",
    "  return arr[:p] #return selection of p rows\n",
    "  #return #some other methods\n",
    "    \n",
    "def test(W,g):\n",
    "  n = 50\n",
    "  x = np.transpose(x_test[:n])\n",
    "  y = np.zeros([k,n])\n",
    "  for i in range(n):\n",
    "    y[y_test[i]][i] = 1\n",
    "\n",
    "  y_hat = []\n",
    "  for i in range(n):\n",
    "    y_hat.append(np.array(g(np.matmul(W,np.array(x[:,i])))))\n",
    "  y_hat = np.transpose(np.array(y_hat))\n",
    "\n",
    "  count = 0\n",
    "  for i in range(n):\n",
    "    if(np.argmax(y_hat[:,i]) != np.nonzero(y[:,i])[0][0]):\n",
    "      count += 1\n",
    "\n",
    "  return str((count / n) * 100) + '% fail'\n",
    "\n",
    "def test_yhat(i_sets, Ws):\n",
    "  n = 50\n",
    "  #x = np.transpose(x_test[:n])\n",
    "  x = np.transpose(pca.transform(x_test))\n",
    "\n",
    "  y_hat = np.zeros([k,n]) #kxn\n",
    "  for t in range(T):\n",
    "    x_tilt = [] #pxn\n",
    "    i_set = i_sets[t]\n",
    "    for i in i_set:\n",
    "      x_tilt.append(x[i])\n",
    "    x_tilt = np.array(x_tilt)\n",
    "\n",
    "    W = Ws[t]\n",
    "    \n",
    "    new_y_hat = []\n",
    "    for i in range(n):\n",
    "      new_y_hat.append(y_hat[:,i] + np.matmul(W,x_tilt[:,i]))\n",
    "    y_hat = np.transpose(new_y_hat) #kxn\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "      if(np.argmax(y_hat[:,i]) != np.nonzero(y[:,i])[0][0]):\n",
    "        count += 1\n",
    "          \n",
    "  return \"total \" + str( (count / n) * 100) + '% fail'\n",
    "\n",
    "result = stagewise_regression(x,y,GEN,L,g,n,d,k,thres,p,T)\n",
    "print(test_yhat(result[0], result[1])) #% with logit g, 66% with lin g\n",
    "#print(test(generalized_least_squares(x,y,W0,L,g,n,d,k,thres),g)) #% with logit g, 16% with lin g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrated_least_squares(x,y,W0,thres): \n",
    "  def clip(v, s=1):\n",
    "    #reference: https://gist.github.com/daien/1272551/edd95a6154106f8e28209a1c7964623ef8397246\n",
    "    n, = v.shape  # will raise ValueError if v is not 1-D\n",
    "    # check if we are already on the simplex\n",
    "    if v.sum() == s and np.alltrue(v >= 0):\n",
    "        # best projection: itself!\n",
    "        return v\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = float(cssv[rho] - s) / rho\n",
    "    # compute the projection by thresholding v using theta\n",
    "    w = (v - theta).clip(min=0)\n",
    "    return w\n",
    "\n",
    "  def is_close(a,b,thres):\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "      for j in range(len(a[i])):\n",
    "        s += abs(a[i][j] - b[i][j])\n",
    "    #print(s)\n",
    "    return s < thres \n",
    "\n",
    "  y_hat = []\n",
    "  for i in range(n):\n",
    "    y_hat.append(np.matmul(W0,np.transpose([x[:,i]]))[:,0])\n",
    "  y_hat = np.transpose(y_hat)\n",
    "\n",
    "  prev_W = W0\n",
    "  W = W0\n",
    "  t = 0\n",
    "  while t == 0 or not is_close(W,prev_W,thres):\n",
    "    t += 1\n",
    "    prev_W = copy.deepcopy(W)\n",
    "\n",
    "    W = np.matmul(np.linalg.inv(np.matmul(np.transpose(x),x)),np.transpose(x))\n",
    "    W = np.matmul(y,W)\n",
    "    \n",
    "    y_tilt = []\n",
    "    for i in range(n):\n",
    "      y_tilt.append(np.add(np.transpose([y_hat[:,i]]),np.matmul(W,np.transpose([x[:,i]])))[:,0])\n",
    "    y_tilt = np.transpose(y_tilt)\n",
    "\n",
    "\n",
    "    u1 = []\n",
    "    u2 = []\n",
    "    u3 = []\n",
    "    for i in range(n):\n",
    "        a = np.argmax(np.absolute(y_tilt[:,i]))\n",
    "        u1.append(a)\n",
    "        u2.append(a**2)\n",
    "        u3.append(a**3)\n",
    "    u = np.array([u1,u2,u3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    W = np.matmul(np.linalg.inv(np.matmul(np.transpose(u),u)),np.transpose(u))\n",
    "    W_tilt = np.matmul(y,W_tilt)\n",
    "\n",
    "    y_hat = []\n",
    "    for i in range(n):\n",
    "      y_hat.append(clip(np.matmul(W_tilt,G(y_tilt[:,i]))[:,0]))\n",
    "    y_hat = np.transpose(y_hat)\n",
    "\n",
    "  return W\n",
    "\n",
    "calibrated_least_squares(x,y,W0,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
