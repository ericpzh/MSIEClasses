{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv_base = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.fc_base = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        x = x.view(x.size(0), 256*6*6)\n",
    "        x = self.fc_base(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(\"C:/Users/ericp/Desktop/pixiv/data/normal/\", \"72390335_p0_square1200.jpg\"))\n",
    "image = cv2.resize(image, (224,224)) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7207, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "images_n = []\n",
    "for file in os.listdir(\"C:/Users/ericp/Desktop/pixiv/data/normal\"):\n",
    "    image = cv2.imread(os.path.join(\"C:/Users/ericp/Desktop/pixiv/data/normal\", file))\n",
    "    image = cv2.resize(image, (224, 224)) \n",
    "    #blue_image = image[:,:,0]\n",
    "    #green_image = image[:,:,1]\n",
    "    #red_image = image[:,:,2]\n",
    "    images_n.append(list((np.transpose(image)/255.0).astype('float64')))\n",
    "images_n = np.array(images_n)\n",
    "print(images_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3687, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "images_r = []\n",
    "for file in os.listdir(\"C:/Users/ericp/Desktop/pixiv/data/r18\"):\n",
    "    image = cv2.imread(os.path.join(\"C:/Users/ericp/Desktop/pixiv/data/r18\", file))\n",
    "    image = cv2.resize(image, (224, 224)) \n",
    "    #blue_image = image[:,:,0]\n",
    "    #green_image = image[:,:,1]\n",
    "    #red_image = image[:,:,2]\n",
    "    images_r.append(list((np.transpose(image)/255.0).astype('float64')))\n",
    "images_r = np.array(images_r)\n",
    "print(images_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.concatenate((images_n, images_r), axis = 0), \n",
    "    np.concatenate((np.zeros(len(images_n)).astype('float64'), np.ones(len(images_r)).astype('float64')), axis = 0), \n",
    "    test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = torch.from_numpy(self.X[idx])\n",
    "        label = torch.tensor(self.Y[idx], dtype=torch.long) \n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = OurDataset(X_train,  y_train)\n",
    "testData = OurDataset(X_test,  y_test)\n",
    "trainLoader = DataLoader(trainData, batch_size=128, shuffle=True, num_workers=0)\n",
    "testLoader = DataLoader(testData, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.000000\n",
      "E: 0; B: 0; Loss: 6.899937; ||g||: 5.267571\n",
      "E: 0; B: 1; Loss: 6.453909; ||g||: 12.648347\n",
      "E: 0; B: 2; Loss: 1.373117; ||g||: 30.166508\n",
      "E: 0; B: 3; Loss: 6.621624; ||g||: 6.944893\n",
      "E: 0; B: 4; Loss: 5.642673; ||g||: 18.133717\n",
      "E: 0; B: 5; Loss: 51.937539; ||g||: 747.667148\n",
      "E: 0; B: 6; Loss: 6.413090; ||g||: 8.591099\n",
      "E: 0; B: 7; Loss: 5.513053; ||g||: 22.229567\n",
      "E: 0; B: 8; Loss: 134.822683; ||g||: 1433.180248\n",
      "E: 0; B: 9; Loss: 6.582153; ||g||: 2.634963\n",
      "E: 0; B: 10; Loss: 6.469398; ||g||: 3.857432\n",
      "E: 0; B: 11; Loss: 6.397728; ||g||: 7.439692\n",
      "E: 0; B: 12; Loss: 6.319406; ||g||: 6.231516\n",
      "E: 0; B: 13; Loss: 6.113776; ||g||: 10.710555\n",
      "E: 0; B: 14; Loss: 5.689651; ||g||: 7.021605\n",
      "E: 0; B: 15; Loss: 5.364249; ||g||: 9.186271\n",
      "E: 0; B: 16; Loss: 5.717992; ||g||: 3.759515\n",
      "E: 0; B: 17; Loss: 4.811392; ||g||: 4.118954\n",
      "E: 0; B: 18; Loss: 4.494277; ||g||: 3.532886\n",
      "E: 0; B: 19; Loss: 4.034882; ||g||: 3.099444\n",
      "E: 0; B: 20; Loss: 3.922315; ||g||: 1.990306\n",
      "E: 0; B: 21; Loss: 3.331734; ||g||: 2.008424\n",
      "E: 0; B: 22; Loss: 4.417800; ||g||: 2.601189\n",
      "E: 0; B: 23; Loss: 3.804101; ||g||: 1.766185\n",
      "E: 0; B: 24; Loss: 3.383602; ||g||: 2.046698\n",
      "E: 0; B: 25; Loss: 3.673883; ||g||: 3.551345\n",
      "E: 0; B: 26; Loss: 3.928139; ||g||: 38.950101\n",
      "E: 0; B: 27; Loss: 2.955215; ||g||: 2.589210\n",
      "E: 0; B: 28; Loss: 4.133805; ||g||: 5.974534\n",
      "E: 0; B: 29; Loss: 4.312527; ||g||: 4.066903\n",
      "E: 0; B: 30; Loss: 3.159620; ||g||: 5.222618\n",
      "E: 0; B: 31; Loss: 3.269733; ||g||: 2.318260\n",
      "E: 0; B: 32; Loss: 3.244431; ||g||: 2.149658\n",
      "E: 0; B: 33; Loss: 3.102125; ||g||: 2.154767\n",
      "E: 0; B: 34; Loss: 2.903818; ||g||: 2.158011\n",
      "E: 0; B: 35; Loss: 2.979678; ||g||: 2.422390\n",
      "E: 0; B: 36; Loss: 2.621142; ||g||: 2.327172\n",
      "E: 0; B: 37; Loss: 2.790813; ||g||: 2.684689\n",
      "E: 0; B: 38; Loss: 3.242665; ||g||: 3.956247\n",
      "E: 0; B: 39; Loss: 2.643356; ||g||: 3.732433\n",
      "E: 0; B: 40; Loss: 2.683605; ||g||: 3.721136\n",
      "E: 0; B: 41; Loss: 2.296679; ||g||: 3.469002\n",
      "E: 0; B: 42; Loss: 1.949717; ||g||: 3.238563\n",
      "E: 0; B: 43; Loss: 1.711066; ||g||: 3.212261\n",
      "E: 0; B: 44; Loss: 1.546475; ||g||: 3.387136\n",
      "E: 0; B: 45; Loss: 1.439859; ||g||: 4.143088\n",
      "E: 0; B: 46; Loss: 1.521957; ||g||: 6.690835\n",
      "E: 0; B: 47; Loss: 1.306224; ||g||: 18.865234\n",
      "E: 0; B: 48; Loss: 1.573042; ||g||: 7.395404\n",
      "E: 0; B: 49; Loss: 1.522801; ||g||: 30.323004\n",
      "E: 0; B: 50; Loss: 1.009419; ||g||: 6.696875\n",
      "E: 0; B: 51; Loss: 1.195396; ||g||: 13.740746\n",
      "E: 0; B: 52; Loss: 1.469527; ||g||: 7.644319\n",
      "E: 0; B: 53; Loss: 0.916866; ||g||: 3.479853\n",
      "E: 0; B: 54; Loss: 0.852455; ||g||: 2.530782\n",
      "E: 0; B: 55; Loss: 0.763974; ||g||: 2.662742\n",
      "E: 0; B: 56; Loss: 0.790209; ||g||: 3.830729\n",
      "E: 0; B: 57; Loss: 1.012598; ||g||: 17.879556\n",
      "Test Accuracy: 66.295884\n",
      "E: 1; B: 0; Loss: 2.271662; ||g||: 11.927240\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=0)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def test(net, testLoader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (data,target) in testLoader:\n",
    "            output = net(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        print(\"Test Accuracy: %f\" % (100.*correct/len(testLoader.dataset)))\n",
    "\n",
    "test(net, testLoader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    net.train()\n",
    "    for batch_idx, (data, target) in enumerate(trainLoader):\n",
    "        pred = net(data)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        gn = 0\n",
    "        for f in net.parameters():\n",
    "            gn = gn + torch.norm(f.grad)\n",
    "        print(\"E: %d; B: %d; Loss: %f; ||g||: %f\" % (epoch, batch_idx, loss, gn))\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    test(net, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
